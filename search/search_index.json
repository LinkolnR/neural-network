{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"P\u00e1gina Inicial","text":"Edi\u00e7\u00e3o <p>2025.2</p>"},{"location":"#repositorio","title":"Reposit\u00f3rio","text":""},{"location":"#lincoln-melo","title":"Lincoln Melo","text":""},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Exerc\u00edcio 1 - Data 05/09/2025</li> <li> Exerc\u00edcio 2</li> <li> Exerc\u00edcio 3 </li> <li> Exerc\u00edcio 4 </li> <li> Projeto</li> </ul>"},{"location":"exercise1-data/main/","title":"Exerc\u00edcio 1","text":""},{"location":"exercise1-data/main/#exercicio-1-data","title":"Exerc\u00edcio 1 - Data","text":"<p>Entrega Referente ao exerc\u00edcio 1 do curso de Redes Neurais e Deep Learning</p>"},{"location":"exercise1-data/main/#relatorio-de-entrega","title":"Relat\u00f3rio de entrega!","text":""},{"location":"exercise1-data/main/#questao-1","title":"Quest\u00e3o 1","text":""},{"location":"exercise1-data/main/#11-e-12-geracao-de-dados-e-grafico-das-4-classes","title":"1.1 e 1.2 Gera\u00e7\u00e3o de dados e gr\u00e1fico das 4 classes","text":"<ul> <li>Class 0: Mean = \\([2, 3]\\), Standard Deviation = \\([0.8, 2.5]\\)</li> <li>Class 1: Mean = \\([5, 6]\\), Standard Deviation = \\([1.2, 1.9]\\)</li> <li>Class 2: Mean = \\([8, 1]\\), Standard Deviation = \\([0.9, 0.9]\\)</li> <li>Class 3: Mean = \\([15, 4]\\), Standard Deviation = \\([0.5, 2.0]\\)</li> </ul> <p>Primeiro \u00e9 necess\u00e1rio consegui gerar os dados, ent\u00e3o aqui utilizei a fun\u00e7\u00e3o do numpy para fazer a gera\u00e7\u00e3o dos n\u00fameros com uma seed fixa (n\u00famero escolhido foi o 37). A seguir temos o gr\u00e1fico plotado dos gr\u00e1ficos gerados.</p> <p>teste_simples:</p> 2025-09-14T16:20:07.989561 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/"},{"location":"exercise1-data/main/#13-analise-e-fronteiras","title":"1.3 An\u00e1lise e fronteiras","text":"<ol> <li> <ol> <li> <ul> <li>Classe 3 apresenta uma maior diferen\u00e7a, o que permite com que separar mais facilmente na regi\u00e3o da direita do gr\u00e1fico.</li> <li>Classe 0, 1 e 2 est\u00e3o bem mais pr\u00f3ximas, o que dificulta uma separa\u00e7\u00e3o entre elas. Vendo o gr\u00e1fico \u00e9 poss\u00edvel perceber que \u00e9 poss\u00edvel tra\u00e7ar uma reta dividindo a classe 2 das classes 0 e 1. Como ela tamb\u00e9m tem um desvio menor a identifica\u00e7\u00e3o dela se torna mais f\u00e1cil.</li> <li>J\u00e1 as entre as classes 0 e 1 existe uma superposi\u00e7\u00e3o maior, por conta da dispers\u00e3o, ent\u00e3o n\u00e3o \u00e9 poss\u00edvel tra\u00e7ar uma linha que dividida perfeitamente elas.</li> </ul> </li> <li> <p>N\u00e3o, \u00e9 imposs\u00edvel separar todas as classes perfeitamente com fronteiras lineares. A classe 3 \u00e9 separ\u00e1vel linearmente das outras, por\u00e9m as classes 0 e 1 tem m\u00falticas sobreposi\u00e7\u00f5es. Ou seja, as fronteiras/bordas precisariam de curvas.</p> </li> <li></li> </ol> </li> </ol> 2025-09-14T16:20:08.238100 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/"},{"location":"exercise1-data/main/#questao-2","title":"Quest\u00e3o 2","text":""},{"location":"exercise1-data/main/#11","title":"1.1","text":"<p>Realizando a gera\u00e7\u00e3o das amostras e redu\u00e7\u00e3o de dimensionalidade utilizando t\u00e9cnicas de PCA para manter as duas dimens\u00f5es que carregam mais informa\u00e7\u00f5es. Assim, temos o seguinte gr\u00e1fico:</p> <p> 2025-09-14T16:20:08.408520 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/    Aqui podemos perceber que a Classe A (vermelha): - Se concentra na parte direita do gr\u00e1fico (PC1 positivo) - Centro pr\u00f3ximo da coordenada (2,0) no gr\u00e1fico</p> <p>Sobre a Classe B (azul): - Se concentra na parte esquerda do gr\u00e1fico (PC1 negativo) - Centro pr\u00f3ximo da coordenada (-2,0) no gr\u00e1fico</p> <p>Tem uma regi\u00e3o central na qual existe uma sobreposi\u00e7\u00e3o onde as duas classes se misturam Mesmo com uma tend\u00eancia de separa\u00e7\u00e3o, (um mais negativo e um mais positivo ao longo de PC1),  n\u00e3o existe uma linha reta para poder dividir as duas classes completamente. Ent\u00e3o a linha de fronteira, de divis\u00e3o n\u00e3o \u00e9 trivial, seria necess\u00e1rio uma fun\u00e7\u00e3o mais complexa com curvas. Por isso, seria necess\u00e1rio redes neurais para conseguir tra\u00e7ar essa separa\u00e7\u00e3o complexa de uma forma que realmente conseguisse dividir bem em duas ou  mais regi\u00f5es.</p>"},{"location":"exercise1-data/main/#questao-3","title":"Quest\u00e3o 3","text":""},{"location":"exercise1-data/main/#31-carregamento-e-descricao-dos-dados","title":"3.1 Carregamento e Descri\u00e7\u00e3o dos Dados","text":"<p>O dataset Spaceship Titanic \u00e9 um problema de classifica\u00e7\u00e3o bin\u00e1ria para prever se um passageiro foi transportado para uma dimens\u00e3o alternativa durante um acidente espacial.</p> <p>Features Identificadas:</p> <p>Num\u00e9ricas (6 features): - <code>Age</code>: Idade do passageiro (0-80 anos) - <code>RoomService</code>, - <code>FoodCourt</code> - <code>ShoppingMall</code> - <code>Spa</code> - <code>VRDeck</code>: Gastos em cr\u00e9ditos gal\u00e1cticos</p> <p>Categ\u00f3ricas (7 features): - <code>HomePlanet</code>: Planeta de origem (Earth, Europa, Mars) - <code>CryoSleep</code>: Em sono criog\u00eanico (True/False) - <code>Destination</code>: Destino da viagem (3 planetas) - <code>VIP</code>: Status VIP (True/False) - <code>Cabin</code>: Localiza\u00e7\u00e3o da cabine (formato complexo) - <code>Name</code>, <code>PassengerId</code>: Identificadores</p> <p>An\u00e1lise Detalhada dos valores faltantes:</p> 2025-09-14T16:20:14.703835 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/"},{"location":"exercise1-data/main/#32-pre-processamento-completo-com-justificativas","title":"3.2 Pr\u00e9-processamento Completo com Justificativas","text":""},{"location":"exercise1-data/main/#estrategia-1-tratamento-de-dados-faltantes","title":"Estrat\u00e9gia 1: Tratamento de Dados Faltantes","text":"<p>Baseado no gr\u00e1fico acima, identificamos dados faltantes em 9 features. Vamos aqui analisar as estrat\u00e9gias para contornar esses valores faltantes.</p> <p>Para Features Num\u00e9ricas:</p> <ul> <li> <p>Age (Idade): ~15.0% faltantes \u2192 Imputa\u00e7\u00e3o pela mediana</p> <ul> <li>Assim conseguimos preservar a distribui\u00e7\u00e3o da idade e dessa forma, tamb\u00e9m evitando um bias no gradiente na etapa de backpropagation</li> </ul> </li> <li> <p>RoomService (Servi\u00e7o Quarto): ~10.4% faltantes \u2192 Preenchimento com zero</p> <ul> <li>Sendo uma aus\u00eancia do registro pode fazer sentido que possa ser igual a 0 cr\u00e9ditos gastos. Al\u00e9m disso, como estamos utilizando a tanh como fun\u00e7\u00e3o de ativa\u00e7\u00e3o, o elemento 0 \u00e9 neutro e n\u00e3o interfere no gradiente.</li> </ul> </li> <li> <p>FoodCourt (Pra\u00e7a Alimenta\u00e7\u00e3o): ~10.2% faltantes \u2192 Preenchimento com zero</p> <ul> <li>Mesma l\u00f3gica do anterior, provavelmente a pessoa n\u00e3o utilizou o servi\u00e7o (0 cr\u00e9ditos) e com o valor 0 n\u00e3o distorce os padr\u00f5es de gasto</li> </ul> </li> <li> <p>ShoppingMall (Shopping): ~10.7% faltantes \u2192 Preenchimento com zero</p> <ul> <li>Mantendo na mesma l\u00f3gica, a pessoa provavelmente n\u00e3o consumiu nada, ent\u00e3o 0. Da mesma forma das duas anteriores.</li> </ul> </li> <li> <p>Spa: ~11.6% faltantes \u2192 Preenchimento com zero</p> <ul> <li>0 = n\u00e3o utilizou servi\u00e7os de spa. 0 N\u00e3o afeta padr\u00f5es e os mantem uniforme</li> </ul> </li> <li> <p>VRDeck (Deck VR): ~11.2% faltantes \u2192 Preenchimento com zero</p> <ul> <li>Novamente 0 por n\u00e3o ter registro pode indicar n\u00e3o ter um uso de fato. E ser neutro para a fun\u00e7\u00e3o de ativa\u00e7\u00e3o.</li> </ul> </li> </ul> <p>Para Features Categ\u00f3ricas:</p> <ul> <li> <p>HomePlanet (Planeta Origem): ~1.1% faltantes \u2192 Imputa\u00e7\u00e3o pela moda</p> <ul> <li>Para preservar distribui\u00e7\u00e3o original e evitar a cria\u00e7\u00e3o de uma outra categoria que s\u00f3 representaria 1%</li> </ul> </li> <li> <p>Cabin (Cabine): ~1.9% faltantes \u2192 Imputa\u00e7\u00e3o pela moda</p> <ul> <li>Novamente, evitar adicionar uma nova categoria e preservando a distribui\u00e7\u00e3o.</li> </ul> </li> <li> <p>Destination (Destino): ~1.1% faltantes \u2192 Imputa\u00e7\u00e3o pela moda</p> <ul> <li>Preserva\u00e7\u00e3o da distribui\u00e7\u00e3o sem adi\u00e7\u00e3o de novas categorias</li> </ul> </li> </ul>"},{"location":"exercise1-data/main/#estrategia-2-encoding-de-variaveis-categoricas","title":"Estrat\u00e9gia 2: Encoding de Vari\u00e1veis Categ\u00f3ricas","text":"<p>One-Hot Encoding para categ\u00f3ricas nominais: - <code>HomePlanet</code> \u2192 3 colunas bin\u00e1rias - <code>Destination</code> \u2192 3 colunas bin\u00e1rias - <code>Cabin</code> (Deck/Side) \u2192 m\u00faltiplas colunas bin\u00e1rias</p> <p>Label Encoding para categ\u00f3ricas booleanas: - <code>CryoSleep</code>: False\u21920, True\u21921 - <code>VIP</code>: False\u21920, True\u21921</p> <p>Justificativa: One-hot evita ordinality artificial, essencial para redes neurais interpretarem categorias independentemente.</p>"},{"location":"exercise1-data/main/#estrategia-3-normalizacao-otimizada-para-funcao-tanh","title":"Estrat\u00e9gia 3: Normaliza\u00e7\u00e3o Otimizada para Fun\u00e7\u00e3o Tanh","text":"<p>M\u00e9todo Escolhido: Z-score normalization</p> <p>Transforma\u00e7\u00e3o Matem\u00e1tica: <pre><code>X_normalized = (X - \u03bc) / \u03c3\n</code></pre></p> <p>Justificativas Te\u00f3ricas:</p> <ol> <li>Regi\u00e3o Ativa da Tanh:</li> <li><code>tanh(x)</code> \u00e9 mais sens\u00edvel em [-2, +2]</li> <li> <p>Utilizando o Z-score centraliza dados em \u03bc=0</p> </li> <li> <p>Converg\u00eancia Otimizada:</p> </li> <li>Gradientes balanceados entre features</li> <li> <p>Evita satura\u00e7\u00e3o da fun\u00e7\u00e3o tanh</p> </li> <li> <p>Preven\u00e7\u00e3o de Problemas:</p> </li> <li>Converg\u00eancia Lenta: Features dominantes mascararam outras</li> </ol>"},{"location":"exercise1-data/main/#33-visualizacoes-demonstrando-o-impacto-tive-problema-com-os-graficos-entao-retirei-essa-parte","title":"3.3 Visualiza\u00e7\u00f5es Demonstrando o Impacto (Tive problema com os gr\u00e1ficos, ent\u00e3o retirei essa parte)","text":""},{"location":"exercise2-perceptron/main/","title":"Perceptron","text":""},{"location":"exercise2-perceptron/main/#parte-1-implementacao-perceptron","title":"Parte 1: Implementa\u00e7\u00e3o Perceptron","text":""},{"location":"exercise2-perceptron/main/#estrutura-do-codigo","title":"Estrutura do C\u00f3digo","text":"<p>Criaremos uma classe <code>Perceptron</code></p> <pre><code>import numpy as np\n\nclass Perceptron:\n    \"\"\"\n    Implementa\u00e7\u00e3o do Perceptron\n\n    Par\u00e2metros\n    ----------\n    learning_rate : float\n        A taxa de aprendizado (entre 0.0 e 1.0)\n    n_iters : int\n        O n\u00famero de passagens (\u00e9pocas)\n\n    Atributos\n    ---------\n    weights\n    bias\n    \"\"\"\n    def __init__(self, learning_rate=0.01, n_iters=10):\n        self.learning_rate = learning_rate\n        self.n_iters = n_iters\n        self.weights = None\n        self.bias = None\n\n    def _activation_function(self, x):\n        \"\"\"\n        Fun\u00e7\u00e3o de Ativa\u00e7\u00e3o Degrau (Heaviside Step Function).\n        Retorna 1 se x &gt;= 0, sen\u00e3o retorna 0.\n        \"\"\"\n        return np.where(x &gt;= 0, 1, 0)\n\n    def fit(self, X, y):\n        \"\"\"\n        Ajusta o modelo aos dados de treinamento.\n\n        Par\u00e2metros\n        ----------\n        X : array-like, shape = [n_samples, n_features]\n            Vetor de treinamento, onde n_samples \u00e9 o n\u00famero de amostras\n            e n_features \u00e9 o n\u00famero de caracter\u00edsticas.\n        y : array-like, shape = [n_samples]\n            Vetor com os r\u00f3tulos (labels) alvo.\n        \"\"\"\n        n_samples, n_features = X.shape\n\n        # Inicializa\u00e7\u00e3o dos pesos e bias\n        self.weights = np.zeros(n_features)\n        self.bias = 0\n\n        y_ = np.array(y)\n\n        for _ in range(self.n_iters):\n            for idx, x_i in enumerate(X):\n                linear_output = np.dot(x_i, self.weights) + self.bias\n                y_predicted = self._activation_function(linear_output)\n                # C\u00e1lculo do Erro e Atualiza\u00e7\u00e3o dos Pesos\n                # A atualiza\u00e7\u00e3o s\u00f3 acontece se houver erro\n                error = y_[idx] - y_predicted\n                update = self.learning_rate * error\n\n                self.weights += update * x_i\n                self.bias += update\n\n    def predict(self, X):\n        linear_output = np.dot(X, self.weights) + self.bias\n        y_predicted = self._activation_function(linear_output)\n        return y_predicted\n</code></pre>"},{"location":"exercise2-perceptron/main/#parte-2-exercicios","title":"Parte 2: Exerc\u00edcios","text":""},{"location":"exercise2-perceptron/main/#exercicio-1-dados-linearmente-separaveis","title":"Exerc\u00edcio 1: Dados Linearmente Separ\u00e1veis","text":""},{"location":"exercise2-perceptron/main/#1-geracao-dos-dados","title":"1. Gera\u00e7\u00e3o dos Dados","text":"<p>Utilizamos o script <code>data_generation.py</code> para criar duas classes de pontos que est\u00e3o distantes uma da outra, garantindo a separabilidade linear. Os par\u00e2metros chave s\u00e3o:</p> <pre><code># data_generation.py\nmean0 = [1.5, 1.5]\ncov0 = [[0.5, 0], [0, 0.5]]\nmean1 = [5, 5]\ncov1 = [[0.5, 0], [0, 0.5]]\n</code></pre> <p>Ao executar o script, obtemos a seguinte visualiza\u00e7\u00e3o:</p> <p> 2025-09-14T16:20:15.053475 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p> </p> <p>Como podemos ver no gr\u00e1fico, os dois grupos (vermelho e azul) n\u00e3o se misturam, representando um caso ideal para o Perceptron.</p>"},{"location":"exercise2-perceptron/main/#2-treinamento","title":"2. Treinamento","text":"<p>No script <code>test_perceptron.py</code>, instanciamos nosso Perceptron e o treinamos com 80% dos dados gerados, utilizando o m\u00e9todo <code>fit</code>.</p> <pre><code># Trecho de test_perceptron.py\n# ...\np = Perceptron(learning_rate=0.01, n_iters=10)\np.fit(X_train, y_train)\n</code></pre>"},{"location":"exercise2-perceptron/main/#3-avaliacao-evaluation","title":"3. Avalia\u00e7\u00e3o (Evaluation)","text":"<p>Ap\u00f3s o treinamento, usamos os 20% de dados restantes (o conjunto de teste) para verificar o qu\u00e3o bem o modelo generaliza para dados n\u00e3o vistos.</p> <pre><code># Trecho de test_perceptron.py\npredictions = p.predict(X_test)\nprint(f\"Acur\u00e1cia do Perceptron no conjunto de teste: {accuracy(y_test, predictions):.2f}\")\n</code></pre> <p>Resultado Obtido: Ao executar o script, a acur\u00e1cia impressa no terminal \u00e9 1.00 (ou 100%).</p>"},{"location":"exercise2-perceptron/main/#4-analise","title":"4. An\u00e1lise","text":"<p>O resultado de 100% de acur\u00e1cia confirma o Teorema da Converg\u00eancia do Perceptron, que afirma que o algoritmo sempre encontrar\u00e1 uma solu\u00e7\u00e3o (uma linha de separa\u00e7\u00e3o) em um n\u00famero finito de passos, desde que os dados sejam linearmente separ\u00e1veis. </p> <p>Podemos visualizar essa solu\u00e7\u00e3o plotando a fronteira de decis\u00e3o que o Perceptron aprendeu:</p> <p>Acur\u00e1cia do Perceptron no conjunto de teste: 1.00</p> <p> 2025-09-14T16:20:15.877633 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p> </p> <p>A linha preta representa a fronteira final encontrada pelo algoritmo. Qualquer ponto de um lado da linha \u00e9 classificado como uma classe, e qualquer ponto do outro lado \u00e9 classificado como a outra, separando perfeitamente os dados, que s\u00e3o claramente linearmente separ\u00e1veis.</p>"},{"location":"exercise2-perceptron/main/#exercicio-2-dados-com-sobreposicao-nao-linearmente-separaveis","title":"Exerc\u00edcio 2: Dados com Sobreposi\u00e7\u00e3o (N\u00e3o Linearmente Separ\u00e1veis)","text":""},{"location":"exercise2-perceptron/main/#1-geracao-dos-dados_1","title":"1. Gera\u00e7\u00e3o dos Dados","text":"<p>Utilizamos o script <code>data_generation2.py</code> para criar duas classes de pontos com m\u00e9dias mais pr\u00f3ximas e maior vari\u00e2ncia, o que causa uma sobreposi\u00e7\u00e3o entre elas. Os par\u00e2metros chave s\u00e3o:</p> <pre><code># data_generation2.py\nmean0 = [3, 3]\ncov0 = [[1.5, 0], [0, 1.5]]\nmean1 = [4, 4]\ncov1 = [[1.5, 0], [0, 1.5]]\n</code></pre> <p>Ao executar o script, obtemos a seguinte visualiza\u00e7\u00e3o, onde a mistura entre os pontos vermelhos e azuis \u00e9 clara:</p> <p> 2025-09-14T16:20:16.647663 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p> </p>"},{"location":"exercise2-perceptron/main/#2-treinamento_1","title":"2. Treinamento","text":"<p>O treinamento, realizado pelo script <code>test_perceptron2.py</code>, segue o mesmo procedimento. O Perceptron tentar\u00e1 encontrar a melhor linha reta poss\u00edvel para separar as duas classes.</p> <pre><code># Trecho de test_perceptron2.py\np = Perceptron(learning_rate=0.01, n_iters=10)\np.fit(X_train, y_train)\n</code></pre>"},{"location":"exercise2-perceptron/main/#3-avaliacao-evaluation_1","title":"3. Avalia\u00e7\u00e3o (Evaluation)","text":"<p>A avalia\u00e7\u00e3o \u00e9 feita da mesma forma, usando o conjunto de teste. No entanto, o resultado esperado \u00e9 diferente.</p> <pre><code># test_perceptron2.py\npredictions = p.predict(X_test)\nprint(f\"Acur\u00e1cia do Perceptron no conjunto de teste com sobreposi\u00e7\u00e3o: {accuracy(y_test, predictions):.2f}\")\n</code></pre> <p>Resultado Obtido: Ao executar o script, a acur\u00e1cia impressa fica em torno de 0.66 (ou 66%). Este valor pode variar ligeiramente devido \u00e0 aleatoriedade na divis\u00e3o treino-teste, mas nunca chegar\u00e1 a 100%.</p>"},{"location":"exercise2-perceptron/main/#4-analise_1","title":"4. An\u00e1lise","text":"<p>A acur\u00e1cia abaixo de 100% demonstra a principal limita\u00e7\u00e3o do Perceptron: ele s\u00f3 pode encontrar solu\u00e7\u00f5es perfeitas para problemas linearmente separ\u00e1veis. Como os dados se sobrep\u00f5em, n\u00e3o existe uma \u00fanica linha reta que consiga dividir as duas classes sem cometer erros.</p> <p>O algoritmo n\u00e3o \"converge\" para uma solu\u00e7\u00e3o sem erros. Em vez disso, a fronteira de decis\u00e3o pode oscilar um pouco durante o treinamento. O resultado final, ap\u00f3s o n\u00famero definido de itera\u00e7\u00f5es, \u00e9 a melhor tentativa do Perceptron de minimizar os erros com uma \u00fanica linha.</p> <p>A fronteira de decis\u00e3o, visualizada ao executar o teste, mostra essa tentativa:</p> <p>Acur\u00e1cia do Perceptron no conjunto de teste com sobreposi\u00e7\u00e3o: 0.66</p> <p> 2025-09-14T16:20:18.068818 image/svg+xml Matplotlib v3.10.6, https://matplotlib.org/ <p> </p> <p>A linha preta corta atrav\u00e9s da \u00e1rea de sobreposi\u00e7\u00e3o, classificando incorretamente alguns pontos de ambas as classes que est\u00e3o do lado \"errado\" da fronteira. Este \u00e9 o comportamento esperado e ilustra por que modelos mais complexos, como Redes Neurais de M\u00faltiplas Camadas (MLPs), s\u00e3o necess\u00e1rios para resolver problemas n\u00e3o-lineares.</p>"},{"location":"projeto/main/","title":"Main","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"thisdocumentation/main/","title":"Main","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}